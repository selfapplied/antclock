name: CUDA Benchmarks

on:
  workflow_dispatch:
    inputs:
      epochs:
        description: 'Number of epochs for benchmarks'
        required: false
        default: '10'
        type: string
      cuda_version:
        description: 'CUDA version for PyTorch (e.g., cu121, cu118)'
        required: false
        default: 'cu121'
        type: string
  push:
    branches:
      - main
    paths:
      - 'benchmarks/**'
      - 'antclock/**'
      - '.github/workflows/cuda-benchmarks.yml'

permissions:
  contents: read

jobs:
  cuda-benchmark:
    # GitHub-hosted GPU runner with NVIDIA T4 GPU (requires GitHub Team or Enterprise plan)
    runs-on: gpu-t4-4-core
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Check GPU availability
        run: |
          echo "ðŸ” Checking GPU availability..."
          nvidia-smi || echo "âš ï¸ nvidia-smi not available"
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install CUDA dependencies
        run: |
          # Install PyTorch with CUDA support
          pip install --upgrade pip
          CUDA_VERSION="${{ inputs.cuda_version || 'cu121' }}"
          pip install torch torchvision torchaudio --index-url "https://download.pytorch.org/whl/${CUDA_VERSION}"
      
      - name: Install project dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Verify CUDA availability
        run: |
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
      
      - name: Run AntClock Benchmarks (Synthetic + Standard)
        run: |
          export PYTHONPATH="${GITHUB_WORKSPACE}:${PYTHONPATH}"
          echo "ðŸ§¬ Running CE synthetic benchmarks..."
          echo "ðŸŽ¯ Running standard benchmarks (SCAN, COGS, CFQ, PCFG, RPM, Math)..."
          python benchmarks/benchmark.py
      
      - name: Display Standard Benchmark Results
        if: always()
        run: |
          echo "## ðŸŽ¯ Standard AntClock Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "real_benchmark_results.json" ]; then
            echo "### Real Benchmark Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Benchmark | Status | Accuracy | Details |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|--------|----------|---------|" >> $GITHUB_STEP_SUMMARY
            
            # Parse JSON and create summary table
            python3 << 'EOF'
          import json
          import sys
          
          try:
              with open('real_benchmark_results.json', 'r') as f:
                  results = json.load(f)
              
              benchmark_names = {
                  'scan': 'SCAN',
                  'cogs': 'COGS', 
                  'cfq': 'CFQ',
                  'pcfg': 'PCFG',
                  'rpm': 'RPM',
                  'math': 'Math'
              }
              
              for key, name in benchmark_names.items():
                  if key in results.get('results', {}):
                      data = results['results'][key]
                      if 'error' in data:
                          print(f"| {name} | âŒ Failed | N/A | {data['error'][:50]}... |")
                      else:
                          # Try different accuracy keys
                          acc = data.get('test_accuracy', 
                                        data.get('accuracy',
                                        data.get('evaluation', {}).get('test_accuracy', 'N/A')))
                          if isinstance(acc, (int, float)):
                              acc_str = f"{acc:.1%}"
                          else:
                              acc_str = str(acc)
                          print(f"| {name} | âœ… Success | {acc_str} | - |")
                  else:
                      print(f"| {name} | âš ï¸ Not Run | N/A | - |")
          except FileNotFoundError:
              print("| All | âš ï¸ No Results | N/A | Benchmark file not found |")
          except Exception as e:
              print(f"| All | âŒ Error | N/A | {str(e)[:50]} |")
          EOF
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Timestamp:** $(python3 -c "import json; print(json.load(open('real_benchmark_results.json'))['timestamp'])" 2>/dev/null || echo "N/A")" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ No benchmark results file found (real_benchmark_results.json)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Standard Benchmarks Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The standard AntClock benchmarks evaluate the CE framework on:" >> $GITHUB_STEP_SUMMARY
          echo "- **SCAN**: Sequence-to-sequence compositional parsing (16K train, 4K test)" >> $GITHUB_STEP_SUMMARY
          echo "- **COGS**: Semantic parsing compositional generalization (24K train, 3K test)" >> $GITHUB_STEP_SUMMARY
          echo "- **CFQ**: Compositional question answering (10K train, 2K test)" >> $GITHUB_STEP_SUMMARY
          echo "- **PCFG**: Probabilistic context-free grammar parsing (1K train, 200 test)" >> $GITHUB_STEP_SUMMARY
          echo "- **RPM**: Raven's Progressive Matrices visual reasoning (10K train, 1K test)" >> $GITHUB_STEP_SUMMARY
          echo "- **Math**: Mathematical reasoning on SVAMP dataset (1K train, 200 test)" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š Full results are available in the workflow artifacts." >> $GITHUB_STEP_SUMMARY
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            .out/
            real_benchmark_results.json
            section6_empirical_results.json
          if-no-files-found: warn
